{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Neural Inverted Index for Fast and Effective Information Retrieval](#toc0_)\n",
    "\n",
    "---\n",
    "\n",
    "## <a id='toc1_1_'></a>[üìö Notebook Overview](#toc0_)\n",
    "\n",
    "This notebook explores a novel [information retrieval (IR)](https://en.wikipedia.org/wiki/Information_retrieval) framework that utilizes a **differentiable function** to generate a **sorted list of document identifiers** in response to a given **query**.\n",
    "\n",
    "The approach is called **Differentiable Search Index (DSI)**, and was originally proposed in the paper [Transformer Memory as a Differentiable Search Index](https://arxiv.org/pdf/2202.06991.pdf) by researchers at Google Research.\n",
    "\n",
    "**DSI** aims at both encompassing all document's corpus information and executing retrieval within a single **Transformer language model**, instead of adopting the index-then-retrieve pipeline used in most modern IR sytems.\n",
    "\n",
    "The notebook presents the implemented solution, a model **Sequence to Sequence transformer** model `f` that, given a query `q` as input, returns list of document IDs ranked by relevance to the query, and compares its performance with the traditional **TF-IDF** retrieval model, a **Word2Vec** model, and a **Siamese Network model with Triplet Loss**.\n",
    "\n",
    "The proposed solution combines the **DSI** approach with the **Scheduled Sampling** technique for Transformers, inspired by the similar technique described in the paper [Scheduled Sampling for Transformers](https://arxiv.org/abs/1906.07651).\n",
    "\n",
    "We evaluate the performance of the proposed models using the **Mean Average Precision (MAP)** and the **Recall at K** metrics computed on the **MS MARCO** dataset, and we compare the results with several baselines (**TF-IDF**, **Word2Vec**, **Siamese Network** and also other traditional **Transformer** approaches).\n",
    "\n",
    "## <a id='toc1_2_'></a>[üìù Author](#toc0_)\n",
    "\n",
    "**Valerio Di Stefano** - _\"Sapienza\" University of Rome_\n",
    "<br/>\n",
    "Email: [distefano.1898728@studenti.uniroma1.it](mailto:distefano.1898728@studenti.uniroma1.it)\n",
    "\n",
    "## <a id='toc1_3_'></a>[üîó External Links](#toc0_)\n",
    "\n",
    "* **Main Paper**: [Transformer Memory as a Differentiable Search Index](https://arxiv.org/pdf/2202.06991.pdf)\n",
    "\n",
    "  _Authors_: Yi Tay, Vinh Q. Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, Tal Schuster, William W. Cohen, Donald Metzler\n",
    "\n",
    "* **Relevant Paper**: [Understanding Differential Search Index for Text Retrieval](https://arxiv.org/abs/2305.02073)\n",
    "\n",
    "  _Authors_: Xiaoyang Chen, Yanjiang Liu, Ben He, Le Sun, Yingfei Sun\n",
    "\n",
    "* **Relevant Paper**: [Scheduled Sampling for Transformers](https://arxiv.org/abs/1906.07651)\n",
    "\n",
    "    _Authors_: Tsvetomila Mihaylova, Andr√© F. T. Martins\n",
    "\n",
    "* **Project Repository**: [GitHub Repository](https://github.com/valeriodiste/deep_learning_project)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_4_'></a>[üìå Table of Contents](#toc0_)\n",
    "\n",
    "**Table of contents**<a id='toc0_'></a>    \n",
    "\n",
    "- [Neural Inverted Index for Fast and Effective Information Retrieval](#toc1_)    \n",
    "  - [üìö Notebook Overview](#toc1_1_)    \n",
    "  - [üìù Author](#toc1_2_)    \n",
    "  - [üîó External Links](#toc1_3_)    \n",
    "  - [üìå Table of Contents](#toc1_4_)    \n",
    "\n",
    "- [üöÄ Getting Started](#toc2_)    \n",
    "  - [Collect Source Files](#toc2_1_)    \n",
    "  - [Install & Import Libraries](#toc2_2_)    \n",
    "  - [Configuration, Hyperparameters and Constants](#toc2_3_)    \n",
    "  - [Download Data & Resources](#toc2_4_)    \n",
    "\n",
    "- [üíæ Data Preparation](#toc3_)    \n",
    "  - [Word2Vec Model Initialization](#toc3_2_)    \n",
    "  - [Dictionaries Creation & Word2Vec Model Training](#toc3_3_)    \n",
    "  - [Dictionaries Loading](#toc3_4_)    \n",
    "\n",
    "- [üßæ TF-IDF Model](#toc4_)    \n",
    "\n",
    "- [üîù Word2Vec Model](#toc5_)    \n",
    "\n",
    "- [üë¨ Siamese Network with Triplet Loss](#toc6_)    \n",
    "\n",
    "- [ü§ñ Seq2Seq Transformer Model (DSI approach)](#toc7_)    \n",
    "  - [Teacher Forcing Seq2Seq Transformer Model](#toc7_2_)    \n",
    "  - [Autoregressive Seq2Seq Transformer Model](#toc7_3_)    \n",
    "  - [Scheduled Sampling Seq2Seq Transformer Model](#toc7_4_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "# <a id='toc2_'></a>[üöÄ Getting Started](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we check if we are running the notebook on Google colab or locally, defining the `RUNNING_ON_COLAB` constant used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "# Check if running on colab or locally\n",
    "try:\n",
    "    from google.colab import files\n",
    "    RUNNING_IN_COLAB = True\n",
    "    print(\"Running on Google Colab.\")\n",
    "except ModuleNotFoundError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"1_1\"></a>\n",
    "## <a id='toc2_1_'></a>[Collect Source Files](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_1_'></a>[Clone Project's GitHub Repository](#toc0_)\n",
    "\n",
    "We **clone the project's repository** from GitHub to access the source files for datasets, models, evaluation and utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "# Clone the git repository from \"https://github.com/valeriodiste/deep_learning_project\" (for the source files)\n",
    "!git clone https://github.com/valeriodiste/deep_learning_project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_2_'></a>[Pull Latest Files Changes](#toc0_)\n",
    "\n",
    "We also **pull the latest changes** from the repository and store them in the `./deep_learning_project` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "# Change the working directory to the cloned repository\n",
    "%cd /content/deep_learning_project\n",
    "# Pull the latest changes from the repository\n",
    "!git pull origin main\n",
    "# Change the working directory to the parent directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_2\"></a>\n",
    "## <a id='toc2_2_'></a>[Install & Import Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_1_'></a>[Install Libraries](#toc0_)\n",
    "\n",
    "We **install all the necessary libraries** for this notebook.\n",
    "\n",
    "- **`pytorch-lightning`**: A **lightweight PyTorch wrapper** for simplifying PyTorch code.\n",
    "- **`ir_datasets`**: A Python library for accessing **information retrieval datasets** (used to load the **\"MS MARCO\" dataset**).\n",
    "- **`wandb`**: The python package for **Weights & Biases**, a tool for experiment tracking, dataset versioning, and project collaboration (used for **logging and visualization**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "# Install the required packages\n",
    "%%capture\n",
    "%pip install pytorch-lightning\n",
    "%pip install ir_datasets\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_2_'></a>[Import Modules](#toc0_)\n",
    "\n",
    "We then **import the required modules**, including `PyTorch`, `PyTorch Lightning`, `IR Datasets` and `W&B`, plus other useful modules and libraries (`NLTK`, `Scikit Learn`, `Numpy`, `Pandas`, etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the standard libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "\n",
    "# Import the PyTorch libraries and modules\n",
    "import torch\n",
    "\n",
    "# Import the PyTorch Lightning libraries and modules\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Import the ir_datasets\n",
    "import ir_datasets\n",
    "\n",
    "# Import the W&B (Weights & Biases) library\n",
    "import wandb\n",
    "from wandb.sdk import wandb_run\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Import the scikit-learn TF-IDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import the NLTK (Natural Language Toolkit) library\n",
    "import nltk\n",
    "\n",
    "# Import the tqdm library (for the progress bars)\n",
    "if not RUNNING_IN_COLAB:\n",
    "    from tqdm import tqdm\n",
    "else:\n",
    "    from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import our own **custom modules** (cloned from the repository) containing Python classes for **datasets**, **models**, **evaluation**, and **utilities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the custom modules\n",
    "if not RUNNING_IN_COLAB:\n",
    "    # We are running locally (not on Google Colab, import modules from the \"src\" directory in the current directory)\n",
    "    from src.scripts import models, datasets, training, evaluation\n",
    "    from src.scripts.utils import (\n",
    "        print_json, MODEL_TYPES, RANDOM_SEED, MODEL_CHECKPOINTS_FILES, get_preprocessed_text, print_model_evaluation_results\n",
    "    )\n",
    "else:\n",
    "    # We are running on Google Colab (import modules from the pulled repository stored in the \"deep_learning_project\" directory)\n",
    "    from deep_learning_project.src.scripts import models, datasets, training, evaluation\n",
    "    from deep_learning_project.src.scripts.utils import (\n",
    "        print_json, MODEL_TYPES, RANDOM_SEED, MODEL_CHECKPOINTS_FILES, get_preprocessed_text, print_model_evaluation_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_3\"></a>\n",
    "## <a id='toc2_3_'></a>[Configuration, Hyperparameters and Constants](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_1_'></a>[Random Seed](#toc0_)\n",
    "\n",
    "We **seed the random number generators** for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_2_'></a>[Device Configuration](#toc0_)\n",
    "\n",
    "We **set the device** to GPU if available, otherwise we use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_3_'></a>[Database Constants](#toc0_)\n",
    "\n",
    "We **define the constants** used for the **database resources download** and the **dataset creation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max number of queries of the dataset (note that the MS MARCO dataset used contains 6980 queries, numbers higher than this will be ignored)\n",
    "#   Set to -1 to use all the available queries in the MS MARCO dataset used\n",
    "#   NOTE: this will also indirectly influence the number of documents in the final dataset, as only documents that are relevant to at least one of the selected queries will be kept\n",
    "MAX_DATASET_QUERIES = 100\n",
    "\n",
    "# Set the number of relevant documents associated to each query (when \"scoreddocs\" are used, a maximum value of 1_000 documents can be used)\n",
    "#   Set to -1 to use all the available relevant documents for each query in the MS MARCO dataset used\n",
    "#   NOTE: the actual number of relevant documents for some queries might be higher than this value, since the final documents dataset will include all documents\n",
    "#       associated to at least one query, and some queries might be relevant to their own set of documents plus some documents relevant to other queries\n",
    "#       (which will still be added to the list, thus exceeding the defined NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY in these cases)\n",
    "NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY = 10\n",
    "\n",
    "# Wheter to remap doc IDs to new IDs (starting from 0 up until the number of documents in the final documents dataset)\n",
    "REMAP_DOC_IDS = True\n",
    "\n",
    "# Defines wheter to use the MS MARCO documents dataset (very heavy) or the MS MARCO passages dataset (smaller and faster to download and process)\n",
    "USE_DOCUMENTS_DATASETS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_4_'></a>[Models Hyperparameters](#toc0_)\n",
    "\n",
    "We then **define the constant** representing **hyperparameters** used for the **Word2Vec model**, the **Siamese Network model** and for the **Seq2Seq transformer model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max length of the embeddings for both queries and documents for the Word2Vec model (embeddings will be padded or truncated to this length)\n",
    "VECTOR_EMBEDDINGS_SIZE = 128\n",
    "\n",
    "# Define the size of the output vector embeddings of the Siamese network model\n",
    "SIAMESE_EMBEDDINGS_SIZE = 64\n",
    "\n",
    "# Define the max length of the embeddings for both queries and documents for the Transformer model (embeddings will be padded or truncated to this length)\n",
    "TRANSFORMER_DOCUMENT_MAX_TOKENS = 128\n",
    "TRANSFORMER_QUERY_MAX_TOKENS = 32\n",
    "\n",
    "# Define the size of the embeddings for the Encoders of the Seq2Seq Transformer model\n",
    "TRANSFORMER_EMBEDDINGS_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_5_'></a>[Evauation Constants](#toc0_)\n",
    "\n",
    "We also define the constants used for the evaluation of the various models (i.e. to compute the **Mean Average Precision** and the **Recall at K**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of documents K to retrieve for each query and the number of queries N to calculate the mean average precision (MAP@K)\n",
    "MAP_K = 10\n",
    "MAP_N = 10\n",
    "\n",
    "# Define the number of documents K to retrieve for each query to calculate the Recall@K metrics\n",
    "RECALL_K = 1_000\n",
    "\n",
    "# Whether to print the debug information during the MAP@K and Recall@K evaluation of the models\n",
    "PRINT_EVALUATION_DEBUG = True\n",
    "\n",
    "# Whether to evaluate the models (i.e. compute the MAP@K and Recall@K metrics for the trained models on the test datasets)\n",
    "EVALUATE_MODELS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_6_'></a>[Other Constants](#toc0_)\n",
    "\n",
    "We ultimately define the constants used to determine where to save data and models and the flags to enable/disable database rebuild/refresh and the loading of models checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the data folder, onto which the documents and queries dictionaries will be saved\n",
    "DATA_FOLDER = \"src/data\" if not RUNNING_IN_COLAB else \"/content/data\"\n",
    "\n",
    "# Define the path to save models\n",
    "MODELS_FOLDER = \"src/models\" if not RUNNING_IN_COLAB else \"/content/models\"\n",
    "\n",
    "# Force the rebuild of the documents and queries dictionaries (to re-save them to the JSON files)\n",
    "FORCE_DICTIONARIES_REBUILD = False\n",
    "\n",
    "# Refreshes the embeddings of the documents and queries (if set to True, the embeddings will be recomputed and saved to the JSON files, used to change properties of the embeddings, e.g. the EMBEDDINGS_SIZE, without having to rebuild the dictionaries)\n",
    "REFRESH_EMBEDDINGS = False\n",
    "\n",
    "# Whether to load model checkpoints (if they were already saved locally) or not\n",
    "LOAD_MODELS_CHECKPOINTS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_7_'></a>[Local Files Folder Creation](#toc0_)\n",
    "\n",
    "We create the folders to store the data dictionaries and the model's checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders if they do not exist\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    print(f\"Creating the data folder at '{DATA_FOLDER}'...\")\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "if not os.path.exists(MODELS_FOLDER):\n",
    "    print(f\"Creating the models folder at '{MODELS_FOLDER}'...\")\n",
    "    os.makedirs(MODELS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_8_'></a>[Weights & Biases Configuration](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the **Weights & Biases** API key to log the experiments.\n",
    "\n",
    "**‚ö†Ô∏è Note**: Copy and paste your own W&B API key into the `WANDB_API_KEY` constant to see logging results, or set the constant to an empty string to disable W&B logging (this won't plot training results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the WANDB_API_KEY (set to \"\" to disable W&B logging)\n",
    "WANDB_API_KEY = \"2ba6d81dbfe138d5c7fe13aeeeaac296cb88d274\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We configure the **Weights & Biases** logger and API to track the experiments and the model's performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\valer\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: valeriodstfn. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_013932-78h9n4qd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/78h9n4qd/workspace' target=\"_blank\">NONE</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/78h9n4qd/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/78h9n4qd/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B API key provided, logging with W&B enabled.\n"
     ]
    }
   ],
   "source": [
    "# Define the wandb logger, api object, entity name and project name\n",
    "wandb_logger = None\n",
    "wandb_api = None\n",
    "wandb_entity = None\n",
    "wandb_project = None\n",
    "# Check if a W&B api key is provided\n",
    "if WANDB_API_KEY == None:\n",
    "    print(\"No W&B API key provided, please provide a valid key to use the W&B API or set the WANDB_API_KEY variable to an empty string to disable logging\")\n",
    "    raise ValueError(\"No W&B API key provided.\")\n",
    "elif WANDB_API_KEY != \"\":\n",
    "    # Login to the W&B (Weights & Biases) API\n",
    "    wandb.login(key=WANDB_API_KEY, relogin=True)\n",
    "    # Minimize the logging from the W&B (Weights & Biases) library\n",
    "    os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "    logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "    # Initialize the W&B (Weights & Biases) loggger\n",
    "    wandb_logger = WandbLogger(\n",
    "        log_model=\"all\", project=\"dl-dsi-project\", name=\"NONE\")\n",
    "    # Initialize the W&B (Weights & Biases) API\n",
    "    wandb_api = wandb.Api()\n",
    "    # Get the W&B (Weights & Biases) entity name\n",
    "    wandb_entity = wandb_logger.experiment.entity\n",
    "    # Get the W&B (Weights & Biases) project name\n",
    "    wandb_project = wandb_logger.experiment.project\n",
    "    print(\"W&B API key provided, logging with W&B enabled.\")\n",
    "else:\n",
    "    print(\"No W&B API key provided, logging with W&B disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1_4\"></a>\n",
    "## <a id='toc2_4_'></a>[Download Data & Resources](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_1_1_'></a>[Download NLTK Resources](#toc0_)\n",
    "\n",
    "We download the needed NLTK resources for text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\valer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\valer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the needed NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_4_1_2_'></a>[Download MS MARCO Dataset](#toc0_)\n",
    "\n",
    "Download the **MS MARCO** dataset's resources for the `ir_dataset` module (if needed).\n",
    "\n",
    "The `USE_DOCUMENTS_DATASETS` flag is used to determine whether to download the \"documents\" version of the dataset or its \"passages\" version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to download the MS MARCO dataset.\n",
      "Documents and queries dictionaries already exist and will be loaded from the JSON files.\n"
     ]
    }
   ],
   "source": [
    "# Download the MS MARCO dataset (if needed and if the dictionaries need to be built/rebuilt)\n",
    "if FORCE_DICTIONARIES_REBUILD or not os.path.exists(DATA_FOLDER + \"/docs_dict.json\") or not os.path.exists(DATA_FOLDER + \"/queries_dict.json\"):\n",
    "\n",
    "    # Load the MS MARCO dataset\n",
    "    dataset = None\n",
    "    if USE_DOCUMENTS_DATASETS:\n",
    "        # Load https://ir-datasets.com/msmarco-passage.html#msmarco-document/dev\n",
    "        dataset = ir_datasets.load(\"msmarco-document/dev\")\n",
    "    else:\n",
    "        # Load https://ir-datasets.com/msmarco-passage.html#msmarco-passage/dev/small\n",
    "        dataset = ir_datasets.load(\"msmarco-passage/dev/small\")\n",
    "\n",
    "    # Triggers the download of the datasets (if not already downloaded)\n",
    "    dataset.docs_iter().__next__()\n",
    "    dataset.queries_iter().__next__()\n",
    "    dataset.qrels_iter().__next__()\n",
    "    dataset.scoreddocs_iter().__next__()\n",
    "\n",
    "    # Print the dataset structure (i.e. the column names)\n",
    "    print_metadata = False\n",
    "    if print_metadata:\n",
    "        print(\"Docs Metadata:\")\n",
    "        print_json(dataset.docs_metadata(), 2)\n",
    "        print(\"Queries Metadata:\")\n",
    "        print_json(dataset.queries_metadata(), 2)\n",
    "        print(\"Qrels Metadata:\")\n",
    "        print_json(dataset.qrels_metadata(), 2)\n",
    "        print(\"Scored Docs Metadata:\")\n",
    "        print_json(dataset.scoreddocs_metadata(), 2)\n",
    "\n",
    "    # Print some samples of the dataset\n",
    "    print_database_samples = False\n",
    "    if print_database_samples:\n",
    "        # Print a sample document\n",
    "        print(\"\\nSample Document:\")\n",
    "        print(\"  <doc_id, url, title, body>\"\n",
    "              if USE_DOCUMENTS_DATASETS\n",
    "              else \"  <doc_id, text>\")\n",
    "        doc = dataset.docs_iter().__next__()\n",
    "        print_json(doc, 2)\n",
    "        # Print a sample query\n",
    "        print(\"\\nSample Query:\")\n",
    "        print(\"  <query_id, text>\")\n",
    "        query = dataset.queries_iter().__next__()\n",
    "        print_json(query, 2)\n",
    "        # Print a sample qrel\n",
    "        #   NOTE: the \"relevance\" and \"iteration\" fields are always 1 and \"0\" respectively, for all the qrels (qrels only contain relevant pairs of <query_id, doc_id>)\n",
    "        print(\"\\nSample Qrel:\")\n",
    "        print(\"  <query_id, doc_id, relevance, iteration>\")\n",
    "        qrel = dataset.qrels_iter().__next__()\n",
    "        print_json(qrel, 2)\n",
    "        # Print a sample scored doc\n",
    "        print(\"\\nSample Scored Doc:\")\n",
    "        print(\"  <query_id, doc_id, score>\")\n",
    "        scored_doc = dataset.scoreddocs_iter().__next__()\n",
    "        print_json(scored_doc, 2)\n",
    "else:\n",
    "    # Print a message indicating that the dictionaries already exist and will be loaded\n",
    "    print(\"No need to download the MS MARCO dataset.\")\n",
    "    print(\"Documents and queries dictionaries already exist and will be loaded from the JSON files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"2\"></a>\n",
    "# <a id='toc3_'></a>[üíæ Data Preparation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_1_'></a>[Data Variables and Constants](#toc0_)\n",
    "\n",
    "We define the `docs_dict` and `queries_dict` dictionaries used to store the documents and queries data.\n",
    "\n",
    "The `docs_dict` dictionary contains, for each document ID, the documents' text and its Word2Vec embedding.\n",
    "\n",
    "The `queries_dict` dictionary contains, for each query ID, the query's text, its Word2Vec embedding and also the list of document IDs for documents relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store the documents and queries (the main dataset)\n",
    "docs_dict = {}\n",
    "queries_dict = {}\n",
    "\n",
    "# Auxiliary dictionary to map the column names to the corresponding index in the ir_datasets tuples\n",
    "IR_DATASET_COLS = {\n",
    "    \"DOCS\": {\"id\": 0, \"url\": 1, \"title\": 2, \"body\": 3} if USE_DOCUMENTS_DATASETS else {\"id\": 0, \"text\": 1},\n",
    "    \"QUERIES\": {\"id\": 0, \"text\": 1},\n",
    "    \"QRELS\": {\"query_id\": 0, \"doc_id\": 1},\n",
    "    \"SCORED_DOCS\": {\"query_id\": 0, \"doc_id\": 1, \"score\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_1\"></a>\n",
    "## <a id='toc3_2_'></a>[Word2Vec Model Initialization](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the `Word2Vec` model to compute the **vector embeddings** of the documents and queries.\n",
    "\n",
    "This model is later **trained on the documents corpus** (using the `Gensim` library) to output vector embeddings of size `VECTOR_EMBEDDINGS_SIZE` for documents and queries.\n",
    "\n",
    "This model is also used as a **baseline** for the evaluation of the final **Seq2Seq** transformer model (we compute the cosine similarity of the output embeddings between a query and the entire documents database to generate the top `K` most relevant documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Word2Vec model to encode the text\n",
    "word2vec_model = models.Word2VecModel(\n",
    "    embeddings_size=VECTOR_EMBEDDINGS_SIZE,\n",
    "    words_window_size=10,\n",
    "    min_word_frequency=0,\n",
    "    learning_rate=0.025,\n",
    "    max_epochs=5,\n",
    "    save_path=MODELS_FOLDER + \"/\" +\n",
    "    MODEL_CHECKPOINTS_FILES[MODEL_TYPES.WORD2VEC]\n",
    ")\n",
    "\n",
    "\n",
    "def load_or_train_word2vec_model(documents_corpus=None):\n",
    "    ''' \n",
    "    Train the word2vec model if the checkpoint file does not exist, otherwise load the model from the checkpoint file \n",
    "\n",
    "    If document_corpus is None or is an empty list, a new document corpus will be created using the documents in the dataset\n",
    "\n",
    "    If a document_corpus is provided (as a list of list of strings representing the words of each document's text), it will be used to train the Word2Vec model\n",
    "    '''\n",
    "    loaded_checkpoint = False\n",
    "    if LOAD_MODELS_CHECKPOINTS:\n",
    "        loaded_checkpoint = word2vec_model.load()\n",
    "    if not loaded_checkpoint:\n",
    "        # Train the Word2Vec model on the documents corpus\n",
    "        print(\"Training the Word2Vec model on the documents corpus...\")\n",
    "        if documents_corpus is None or len(documents_corpus) == 0:\n",
    "            # Build the documents corpus\n",
    "            documents_corpus = [get_preprocessed_text(\n",
    "                docs_dict[doc_id][\"text\"]).split(\" \") for doc_id in docs_dict]\n",
    "        # Train the Word2Vec model\n",
    "        word2vec_model.train(documents_corpus)\n",
    "        print(\"Word2Vec model training completed.\")\n",
    "    else:\n",
    "        print(\"Word2Vec model loaded from the checkpoint file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_2\"></a>\n",
    "\n",
    "## <a id='toc3_3_'></a>[Dictionaries Creation & Word2Vec Model Training](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the **documents** and **queries** dictionaries if needed (or if the `FORCE_DICTIONARIES_REBUILD` flag is set to `True`).\n",
    "\n",
    "Documents and queries **vector embeddings** are also created, using the `Word2Vec` model trained on the documents' corpus.\n",
    "\n",
    "If the `REMAP_DOC_IDS` flag is set to `True`, document IDs are also **remapped to new IDs** to avoid gaps in the dictionary.\n",
    "\n",
    "We ultimately **save the dictionaries** into local files in the `DATA_FOLDER` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dictionaries need to be built/rebuilt\n",
    "if FORCE_DICTIONARIES_REBUILD or not os.path.exists(DATA_FOLDER + \"/docs_dict.json\") or not os.path.exists(DATA_FOLDER + \"/queries_dict.json\"):\n",
    "\n",
    "    print(\"The documents and queries dictionaries files do not exist, creating them...\")\n",
    "\n",
    "    # Build a queries dictionary, containing the query_id as key, and as values both the query text and a list of associated relevant documents (as doc_id) taken from the scored documents (list of the 1000 relevant documents to the query)\n",
    "    number_of_queries = MAX_DATASET_QUERIES \\\n",
    "        if 0 < MAX_DATASET_QUERIES < dataset.queries_count() \\\n",
    "        else dataset.queries_count()\n",
    "    use_scored_docs_for_relevant_documents = True\n",
    "    for query in tqdm(dataset.queries_iter(), \"Building the queries dictionary\", number_of_queries):\n",
    "        if len(queries_dict) >= number_of_queries:\n",
    "            break\n",
    "        query_id = query[IR_DATASET_COLS[\"QUERIES\"][\"id\"]]\n",
    "        query_text = query[IR_DATASET_COLS[\"QUERIES\"][\"text\"]]\n",
    "        queries_dict[query_id] = {\n",
    "            \"text\": query_text,\n",
    "            \"embedding\": None,\n",
    "            \"relevant_docs\": []\n",
    "        }\n",
    "    # Add the relevant documents to the queries dictionary\n",
    "    doc_ids_with_rel = set()\n",
    "    # First, add the relevant document(s) using the qrels (to ensure the most relevant documents are added first)\n",
    "    for qrel in tqdm(dataset.qrels_iter(), \"Adding relevant documents to queries (using qrels)\", dataset.qrels_count()):\n",
    "        query_id = qrel[IR_DATASET_COLS[\"QRELS\"][\"query_id\"]]\n",
    "        if query_id not in queries_dict:\n",
    "            continue\n",
    "        doc_id = qrel[IR_DATASET_COLS[\"QRELS\"][\"doc_id\"]]\n",
    "        if NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY < 0 or len(queries_dict[query_id][\"relevant_docs\"]) < NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY:\n",
    "            queries_dict[query_id][\"relevant_docs\"].append(doc_id)\n",
    "            doc_ids_with_rel.add(doc_id)\n",
    "    # Then, add the relevant documents using the scoreddocs (if needed)\n",
    "    # NOTE: the scoreddocs list contains 1000 relevant documents to the query, unordered and without an associated relevance score (these results are less precise than the qrels)\n",
    "    if use_scored_docs_for_relevant_documents:\n",
    "        for scored_doc in tqdm(dataset.scoreddocs_iter(), \"Adding relevant documents to queries (using scoreddocs)\", dataset.scoreddocs_count()):\n",
    "            query_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"query_id\"]]\n",
    "            if query_id not in queries_dict:\n",
    "                continue\n",
    "            doc_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"doc_id\"]]\n",
    "            if NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY < 0 or len(queries_dict[query_id][\"relevant_docs\"]) < NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY:\n",
    "                queries_dict[query_id][\"relevant_docs\"].append(doc_id)\n",
    "                doc_ids_with_rel.add(doc_id)\n",
    "        # Fix the missing relevant documents from the queries dictionary (if the relevant documents list was reduced)\n",
    "        if NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY > 0:\n",
    "            # Re-add to the relevant documents list of each query all the removed documents that will be added to the documents dataset (i.e. in the doc_ids_with_rel set)\n",
    "            for scored_doc in tqdm(dataset.scoreddocs_iter(), \"Fixing missing relevant documents from queries dictionary\", dataset.scoreddocs_count()):\n",
    "                query_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"query_id\"]]\n",
    "                if query_id not in queries_dict:\n",
    "                    continue\n",
    "                doc_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"doc_id\"]]\n",
    "                if doc_id in doc_ids_with_rel and doc_id not in queries_dict[query_id][\"relevant_docs\"]:\n",
    "                    queries_dict[query_id][\"relevant_docs\"].append(doc_id)\n",
    "    print(\n",
    "        f\"Total number of documents relevant to at least one query: {len(doc_ids_with_rel)}\")\n",
    "\n",
    "    # Initialize the corpus of documents (to be used to train the Word2Vec model)\n",
    "    documents_corpus = []\n",
    "\n",
    "    # Build a documents dictionary, containing the doc_id as key, and the attribute \"text\" containing the document text\n",
    "    documents_count = 0\n",
    "    documents_id_remapping = {}\n",
    "    documents_id_remapping_inverse = {}\n",
    "    for doc in tqdm(dataset.docs_iter(), \"Building the documents dictionary\", dataset.docs_count()):\n",
    "        # Add the document and its text to the documents dictionary\n",
    "        doc_id = doc[IR_DATASET_COLS[\"DOCS\"][\"id\"]]\n",
    "        if doc_id not in doc_ids_with_rel:\n",
    "            continue\n",
    "        doc_text = \"\"\n",
    "        if USE_DOCUMENTS_DATASETS:\n",
    "            doc_text = doc[IR_DATASET_COLS[\"DOCS\"][\"title\"]] + \\\n",
    "                \".\\n\" + doc[IR_DATASET_COLS[\"DOCS\"][\"body\"]]\n",
    "        else:\n",
    "            doc_text = doc[IR_DATASET_COLS[\"DOCS\"][\"text\"]]\n",
    "        docs_dict[doc_id] = {\n",
    "            \"text\": doc_text,\n",
    "            \"embedding\": None\n",
    "        }\n",
    "        # Compute the remapped doc_id (if needed)\n",
    "        if REMAP_DOC_IDS:\n",
    "            new_doc_id = str(documents_count)\n",
    "            documents_id_remapping[doc_id] = new_doc_id\n",
    "            documents_id_remapping_inverse[new_doc_id] = doc_id\n",
    "        # Increment the documents count\n",
    "        documents_count += 1\n",
    "        # Add the document text to the corpus\n",
    "        documents_corpus.append(get_preprocessed_text(doc_text).split(\" \"))\n",
    "\n",
    "    # Load or train the Word2Vec model on the documents corpus\n",
    "    load_or_train_word2vec_model(documents_corpus)\n",
    "\n",
    "    # Iterate over documents in the dictionaries to compute the embeddings (and to eventually remap the doc_ids)\n",
    "    new_docs_dict = {}\n",
    "    for doc_id in tqdm(docs_dict, \"Computing document embeddings\" + (\" and remapping doc_ids\" if REMAP_DOC_IDS else \"\")):\n",
    "        # Compute the embedding of the document text\n",
    "        docs_dict[doc_id][\"embedding\"] = \\\n",
    "            word2vec_model.get_embedding((docs_dict[doc_id][\"text\"]))\n",
    "        # Remap the doc_id (if needed)\n",
    "        if REMAP_DOC_IDS:\n",
    "            new_docs_dict[documents_id_remapping[doc_id]] = {\n",
    "                \"text\": docs_dict[doc_id][\"text\"],\n",
    "                \"embedding\": docs_dict[doc_id][\"embedding\"]\n",
    "            }\n",
    "    if REMAP_DOC_IDS:\n",
    "        docs_dict = new_docs_dict\n",
    "    # Iterate over queries in the dictionary to compute the embeddings (and to eventually remap the relevant doc_ids)\n",
    "    for query_id in tqdm(queries_dict, \"Computing query embeddings\" + (\" and remapping relevant doc_ids\" if REMAP_DOC_IDS else \"\")):\n",
    "        # Compute the embedding of the query text\n",
    "        queries_dict[query_id][\"embedding\"] = \\\n",
    "            word2vec_model.get_embedding(queries_dict[query_id][\"text\"])\n",
    "        # Remap the relevant documents (if needed)\n",
    "        if REMAP_DOC_IDS:\n",
    "            current_relevant_docs = queries_dict[query_id][\"relevant_docs\"]\n",
    "            queries_dict[query_id][\"relevant_docs\"] = [\n",
    "                documents_id_remapping[doc_id] for doc_id in current_relevant_docs]\n",
    "\n",
    "    # Print the total number of documents and queries\n",
    "    print(f\"Total number of documents (in built dict): {len(docs_dict)}\")\n",
    "    print(f\"Total number of queries (in built dict): {len(queries_dict)}\")\n",
    "\n",
    "    # Save the 2 dictionaries to 2 JSON files in the \"data\" directory\n",
    "    print(\"Saving the documents and queries dictionaries to the JSON files...\")\n",
    "    with open(DATA_FOLDER + \"/docs_dict.json\", \"w\") as docs_dict_file:\n",
    "        json.dump(docs_dict, docs_dict_file, indent=2)\n",
    "    with open(DATA_FOLDER + \"/queries_dict.json\", \"w\") as queries_dict_file:\n",
    "        json.dump(queries_dict, queries_dict_file, indent=2)\n",
    "    print(\"Created the documents and queries dictionaries and saved them to the files.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_3\"></a>\n",
    "\n",
    "## <a id='toc3_4_'></a>[Dictionaries Loading](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the `documents` and `queries` dictionaries from the local files in the `DATA_FOLDER` dicectory and save them to the corresponding dictionary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the documents and queries dictionaries from the files...\n",
      "  Loaded 979 documents\n",
      "  Loaded 100 queries\n"
     ]
    }
   ],
   "source": [
    "# Load the documents and queries dictionaries from the JSON files\n",
    "print(\"Loading the documents and queries dictionaries from the files...\")\n",
    "with open(DATA_FOLDER + \"/docs_dict.json\", \"r\") as docs_dict_file:\n",
    "    docs_dict = json.load(docs_dict_file)\n",
    "print(f\"  Loaded {len(docs_dict)} documents\")\n",
    "with open(DATA_FOLDER + \"/queries_dict.json\", \"r\") as queries_dict_file:\n",
    "    queries_dict = json.load(queries_dict_file)\n",
    "print(f\"  Loaded {len(queries_dict)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# <a id='toc4_'></a>[üßæ TF-IDF Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_1_1_'></a>[TF-IDF Model Initialization](#toc0_)\n",
    "\n",
    "The first baseline used for the evaluation consists of a **TF-IDF** model (**no machine learning used**).\n",
    "\n",
    "The model, a simple vectorizer built using the `Scikit Learn` library, computes the **TF-IDF scores** for each word and each document in the corpus and stores them in the `tf_idf_matrix` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document IDs\n",
    "doc_ids = list(docs_dict.keys())\n",
    "# Document texts\n",
    "doc_texts = [docs_dict[doc_id]['text'].lower() for doc_id in doc_ids]\n",
    "# Remove empty documents from the list (and their respective IDs)\n",
    "doc_ids, doc_texts = zip(*[(doc_id, doc_text) for doc_id,\n",
    "                           doc_text in zip(doc_ids, doc_texts) if len(doc_text) > 0])\n",
    "\n",
    "# Get the TF-IDF vectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# Fit the vectorizer on the document texts, computing the TF-IDF matrix (an [n_docs]x[vocab_size] matrix with the TF*IDF score value for each word in each document)\n",
    "tf_idf_matrix = tf_idf_vectorizer.fit_transform(doc_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_1_2_'></a>[TF-IDF Model Evaluation](#toc0_)\n",
    "\n",
    "We compute the **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** defined by `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **evaluate the TF-IDF model's performance**.\n",
    "\n",
    "We then **print the results** of the evaluation of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the TF-IDF model...\n",
      "Evaluating TF-IDF model to compute MAP@K...\n",
      "Evaluating TF-IDF model to compute Recall@K...\n",
      "MAP@10 for the TF-IDF model:\n",
      "  > 0.93\n",
      "  Computed on 10 queries\n",
      "  Single queries precision:\n",
      "    Query 873886: 0.9\n",
      "    Query 1051285: 0.9\n",
      "    Query 1051530: 1.0\n",
      "    Query 1051755: 1.0\n",
      "    Query 2798: 1.0\n",
      "    Query 1051108: 0.9\n",
      "    Query 1288: 0.7\n",
      "    Query 1049955: 0.9\n",
      "    Query 1091234: 1.0\n",
      "    Query 1049894: 1.0\n",
      "Recall@1000 for the TF-IDF model:\n",
      "  > 1.0\n",
      "  Computed for query 263670\n"
     ]
    }
   ],
   "source": [
    "if EVALUATE_MODELS:\n",
    "    print(\"Evaluating the TF-IDF model...\")\n",
    "    tf_idf_map_k = evaluation.compute_mean_average_precision_at_k(\n",
    "        MODEL_TYPES.TF_IDF, queries_dict, docs_dict,\n",
    "        k_documents=MAP_K, n_queries=MAP_N,\n",
    "        print_debug=PRINT_EVALUATION_DEBUG,\n",
    "        # Keyword arguments for the TF-IDF model\n",
    "        vectorizer=tf_idf_vectorizer, tfidf_matrix=tf_idf_matrix)\n",
    "    # Evaluate the TF-IDF model (compute the Recall@K)\n",
    "    tf_idf_recall_k = evaluation.compute_recall_at_k(\n",
    "        MODEL_TYPES.TF_IDF, queries_dict, docs_dict,\n",
    "        k_documents=RECALL_K,\n",
    "        print_debug=PRINT_EVALUATION_DEBUG,\n",
    "        # Keyword arguments for the TF-IDF model\n",
    "        vectorizer=tf_idf_vectorizer, tfidf_matrix=tf_idf_matrix)\n",
    "    # Print the evaluation results\n",
    "    print_model_evaluation_results(tf_idf_map_k, tf_idf_recall_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# <a id='toc5_'></a>[üîù Word2Vec Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc5_1_1_1_'></a>[Word2Vec Model Evaluation](#toc0_)\n",
    "\n",
    "We evaluate the `Word2Vec` model initialized in section \"[Word2Vec Model Initialization](#toc3_2_)\" and trained in section \"[Dictionaries Creation & Word2Vec Model Training](#toc3_3_)\" (to generate documents and queries embeddings) by computing the **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **evaluate the Word2Vec model's performance**.\n",
    "\n",
    "Both metrics are computed by using the trained **Word2Vec model** to generate a vector embedding for the given queryes and for all the documents in the corpus, and then calculating the **cosine similarity** between the query embedding and the document embeddings to generate the top `K` most relevant documents.\n",
    "\n",
    "We therefore employ an **index-then-retrieve** approach, which is significantly slower (in the document retrieval phase) than the approach taken for the final **Seq2Seq transformer** model.\n",
    "\n",
    "If the model was not already trained (e.g. in case of documents and queries dictionaries being loaded from local files instead of being generated at runtime), we also **train the model** on the documents corpus.\n",
    "\n",
    "We then **print the results** of the evaluation of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Word2Vec model on the documents corpus...\n",
      "Word2Vec model training completed.\n",
      "Computing the similarity scores between the queries and the documents using the Word2Vec model...\n",
      "Evaluating Word2Vec model to compute MAP@K...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 15606.91it/s]\n",
      "Computing relevance scores for MAP@K for query 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 17184.38it/s]\n",
      "Computing relevance scores for MAP@K for query 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 16869.16it/s]\n",
      "Computing relevance scores for MAP@K for query 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 18473.87it/s]\n",
      "Computing relevance scores for MAP@K for query 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 14259.26it/s]\n",
      "Computing relevance scores for MAP@K for query 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 17101.07it/s]\n",
      "Computing relevance scores for MAP@K for query 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 17196.03it/s]\n",
      "Computing relevance scores for MAP@K for query 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 17217.01it/s]\n",
      "Computing relevance scores for MAP@K for query 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 16681.73it/s]\n",
      "Computing relevance scores for MAP@K for query 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 17178.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Word2Vec model to compute Recall@K...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for Recall@K...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 16965.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for the Word2Vec model:\n",
      "  > 0.53\n",
      "  Computed on 10 queries\n",
      "  Single queries precision:\n",
      "    Query 1038859: 0.7\n",
      "    Query 524699: 0.6\n",
      "    Query 1051422: 0.6\n",
      "    Query 264410: 0.3\n",
      "    Query 811852: 0.2\n",
      "    Query 1050857: 0.2\n",
      "    Query 789332: 0.5\n",
      "    Query 788484: 1.0\n",
      "    Query 1051886: 0.8\n",
      "    Query 786918: 0.4\n",
      "Recall@1000 for the Word2Vec model:\n",
      "  > 1.0\n",
      "  Computed for query 787784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if the word2vec model needs to be trained\n",
    "if not word2vec_model.get_is_trained():\n",
    "    # Train the Word2Vec model on the documents corpus or load it from the checkpoint file\n",
    "    load_or_train_word2vec_model()\n",
    "\n",
    "# Use just the Word2Vec model (with which the embeddings were computed) to compute the similarity scores between the queries and the documents\n",
    "if EVALUATE_MODELS:\n",
    "    print(\"Computing the similarity scores between the queries and the documents using the Word2Vec model...\")\n",
    "    word2vec_map_k = evaluation.compute_mean_average_precision_at_k(\n",
    "        MODEL_TYPES.WORD2VEC, queries_dict, docs_dict,\n",
    "        k_documents=MAP_K, n_queries=MAP_N,\n",
    "        print_debug=PRINT_EVALUATION_DEBUG)\n",
    "    word2vec_recall_k = evaluation.compute_recall_at_k(\n",
    "        MODEL_TYPES.WORD2VEC, queries_dict, docs_dict,\n",
    "        k_documents=RECALL_K,\n",
    "        print_debug=PRINT_EVALUATION_DEBUG)\n",
    "    print_model_evaluation_results(word2vec_map_k, word2vec_recall_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# <a id='toc6_'></a>[üë¨ Siamese Network with Triplet Loss](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc6_1_1_1_'></a>[Siamese Network Model Initialization](#toc0_)\n",
    "\n",
    "We initialize a **Siamese Netork model with Triplet Loss** to act as a third baseline for the evaluation of the finial **Seq2Seq transformer** model.\n",
    "\n",
    "The **hyperparameters** of the model are defined in the `siamese_network_args` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SiameseNetwork model's args\n",
    "siamese_network_args = {\n",
    "    \"input_size\": VECTOR_EMBEDDINGS_SIZE,\n",
    "    \"output_size\": SIAMESE_EMBEDDINGS_SIZE,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"margin\": 1.0,\n",
    "    \"dropout\": 0.0,\n",
    "    \"activation_function\": \"ReLU\"\n",
    "}\n",
    "\n",
    "# Create the Siamese Network model with Triplet Loss\n",
    "siamese_network_model = models.SiameseNetwork(**siamese_network_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc6_1_1_2_'></a>[Siamese Network Dataset Creation](#toc0_)\n",
    "\n",
    "We create a **dataset** to then train and evaluate the **Siamese Network model** using the `SiameseNetworkDataset` class.\n",
    "\n",
    "The dataset consists of **triplets** of **anchor**, **positive** and **negative** samples, where:\n",
    "- **anchor** is a query id;\n",
    "- **positive** is a document ID of a document that is relevant to the corresponding query;\n",
    "- **negative** is a document ID of a document that is **NOT** relevant to the corresponding query.\n",
    "\n",
    "We also plot some **dataset triplet** examples to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Siamese Network's triplets data from src/data/siamese_triplets_dataset.json...\n",
      "Loaded 1001 triplets from src/data/siamese_triplets_dataset.json\n",
      "Number of [query, document+, document-] triplets in the dataset: 1001\n",
      "Example of a triplet:\n",
      "  [query, document+, document-]:  ['1048585', '759', '860']\n",
      "  Query text:  what is paula deen's brother\n",
      "  Positive document text:  Brother monochrome laser printers go beyond just a low initial purchase price; they offer a low cost per page with features such as: Learn More About Brother Black and White Laser Printers. To learn more about Brother monochrome laser printers and how they can help you, click through the products above. 1  ENERGY STAR¬Æ Qualified: : Brother black and white laser printers enter an energy-saving sleep mode after being inactive for a certain period of time, which you can customize.\n",
      "  Negative document text:  Definition of streaming. : relating to or being the transfer of data (such as audio or video material) in a continuous stream especially for immediate processing or playback.\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset for the Siamese Network model\n",
    "#   The dataset will be a list of triplets (anchor_query, positive_document, negative_document)\n",
    "siamese_triplets_dataset = datasets.SiameseNetworkDataset(\n",
    "    queries_dict, docs_dict,\n",
    "    dataset_file_path=DATA_FOLDER + \"/siamese_triplets_dataset.json\",\n",
    "    force_dataset_rebuild=FORCE_DICTIONARIES_REBUILD\n",
    ")\n",
    "\n",
    "# Print the number of triplets in the dataset\n",
    "print(\n",
    "    f\"Number of [query, document+, document-] triplets in the dataset: {len(siamese_triplets_dataset.triplets)}\")\n",
    "\n",
    "# Print an example of a triplet\n",
    "print_triplet_example = True\n",
    "if print_triplet_example:\n",
    "    print(\"Example of a triplet:\")\n",
    "    triplet_example = siamese_triplets_dataset.triplets[0]\n",
    "    print(\"  [query, document+, document-]: \", triplet_example)\n",
    "    # Print the text of the query, the positive document and the negative document\n",
    "    print(\"  Query text: \", queries_dict[triplet_example[0]][\"text\"])\n",
    "    print(\"  Positive document text: \",\n",
    "          docs_dict[triplet_example[1]][\"text\"])\n",
    "    print(\"  Negative document text: \",\n",
    "          docs_dict[triplet_example[2]][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc6_1_1_3_'></a>[Siamese Network Model Training](#toc0_)\n",
    "\n",
    "We train the **Siamese Network model** using the `train_siamese` function of the custom `training` module.\n",
    "\n",
    "At the end of training, if a `WANDB_API_KEY` was provided (and thus the **Weights & Biases logger** was used), we also load the Weights & Biases dashboard to **plot the training results**.\n",
    "\n",
    "If the model was **already trained** and **saved to a checkpoint file** in the `MODEL_CHECKPOINTS_FILES`, and if the `LOAD_MODELS_CHECKPOINTS` is set to `true`, we **load the model** from the checkpoint file instead of training it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">NONE</strong> at: <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/78h9n4qd/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/78h9n4qd/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_folder: src/models/\n",
      "checkpoint_name: siamese_network.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_013943-2otuzx4d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/2otuzx4d/workspace' target=\"_blank\">Siamese Network</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/2otuzx4d/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/2otuzx4d/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type              | Params\n",
      "---------------------------------------------------\n",
      "0 | model        | Sequential        | 74.2 K\n",
      "1 | triplet_loss | TripletMarginLoss | 0     \n",
      "---------------------------------------------------\n",
      "74.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "74.2 K    Total params\n",
      "0.297     Total estimated model params size (MB)\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 25.95it/s, v_num=zx4d]\n",
      "Average training loss for epoch 0:  0.999636709690094\n",
      "Average validation loss for epoch 0:  0.9991834163665771\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 26.65it/s, v_num=zx4d]\n",
      "Average training loss for epoch 1:  0.9994148015975952\n",
      "Average validation loss for epoch 1:  0.9986151456832886\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 32.71it/s, v_num=zx4d]\n",
      "Average training loss for epoch 2:  0.9989949464797974\n",
      "Average validation loss for epoch 2:  0.9978592991828918\n",
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 29.59it/s, v_num=zx4d]\n",
      "Average training loss for epoch 3:  0.9986307621002197\n",
      "Average validation loss for epoch 3:  0.9968227744102478\n",
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 21.44it/s, v_num=zx4d]\n",
      "Average training loss for epoch 4:  0.997823178768158\n",
      "Average validation loss for epoch 4:  0.9954085946083069\n",
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 13.03it/s, v_num=zx4d]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  4.82it/s, v_num=zx4d]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Siamese Network</strong> at: <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/2otuzx4d/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/2otuzx4d/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for the Siamese Network model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/2otuzx4d?jupyter=true' style='border:none;width:100%;height:1000px;'></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model's checkpoint file path\n",
    "model_checkpoint_file = MODELS_FOLDER + \"/\" + \\\n",
    "    MODEL_CHECKPOINTS_FILES[MODEL_TYPES.SIAMESE_NETWORK]\n",
    "\n",
    "# Train or load the Siamese Network model\n",
    "if LOAD_MODELS_CHECKPOINTS and os.path.exists(model_checkpoint_file):\n",
    "    # Load the Siamese Network model from the checkpoint file\n",
    "    print(\n",
    "        \"A checkpoint file for the Siamese Network model exists, loading the model...\")\n",
    "    siamese_network_model = models.SiameseNetwork.load_from_checkpoint(\n",
    "        model_checkpoint_file, **siamese_network_args)\n",
    "    print(\"Checkpoint for the Siamese Network model loaded.\")\n",
    "else:\n",
    "    # Create a new logger for the Siamese Network model\n",
    "    siamese_wandb_logger = None\n",
    "    if wandb_api is not None:\n",
    "        if wandb_logger is not None:\n",
    "            wandb_logger.experiment.finish(quiet=True)\n",
    "        siamese_wandb_logger = WandbLogger(\n",
    "            log_model=\"all\", project=wandb_project, name=\"Siamese Network\")\n",
    "    # Train the Siamese Network model\n",
    "    siamese_training_infos = training.train_siamese(\n",
    "        siamese_dataset=siamese_triplets_dataset,\n",
    "        siamese_model=siamese_network_model,\n",
    "        max_epochs=5,\n",
    "        batch_size=512,\n",
    "        split_ratio=0.8,\n",
    "        logger=siamese_wandb_logger,\n",
    "        save_path=model_checkpoint_file\n",
    "    )\n",
    "    # Show the W&B run's dashboard\n",
    "    if wandb_api is not None:\n",
    "        print(\"Training results for the Siamese Network model:\")\n",
    "        run_id = siamese_training_infos[\"run_id\"]\n",
    "        run_object: wandb_run.Run = wandb_api.run(\n",
    "            f\"{wandb_entity}/{wandb_project}/{run_id}\")\n",
    "        run_object.display(height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc6_1_1_4_'></a>[Siamese Network Model Evaluation](#toc0_)\n",
    "\n",
    "\n",
    "We compute the **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **evaluate the Siamese Network model's performance**.\n",
    "\n",
    "Once again, as for the Word2Vec model (see section \"[Word2Vec Model Initialization](#toc3_3_)\"), both metrics are computed by using the trained **Siamese Network model**, which in turn takes as input the vector embeddings for documents and queries computed using the **Word2Vec model**, to generate a vector embedding of size `SIAMESE_EMBEDDINGS_SIZE` for the given queryes and for all the documents in the corpus, and then calculating the **cosine similarity** between the query embedding and the document embeddings to generate the top `K` most relevant documents.\n",
    "\n",
    "We therefore employ the same **index-then-retrieve** approach used for the Word2Vec model.\n",
    "\n",
    "We then **print the results** of the evaluation of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the Siamese Network model...\n",
      "Evaluating Siamese Network with Triplet Loss model to compute MAP@K...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1929.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 1/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 2000.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 2/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 2005.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 3/10: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1790.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 4/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1921.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 5/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1803.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 6/10: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1970.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 7/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1698.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 8/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1112.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 9/10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for MAP@K for query 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1811.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision at 10 for query 10/10: 0.1\n",
      "Evaluating Siamese Network with Triplet Loss model to compute Recall@K...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relevance scores for Recall@K...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:00<00:00, 1666.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for the Siamese Network with Triplet Loss model:\n",
      "  > 0.030000000000000006\n",
      "  Computed on 10 queries\n",
      "  Single queries precision:\n",
      "    Query 1049774: 0.0\n",
      "    Query 525868: 0.0\n",
      "    Query 526013: 0.1\n",
      "    Query 787784: 0.0\n",
      "    Query 263889: 0.0\n",
      "    Query 1051339: 0.1\n",
      "    Query 1051095: 0.0\n",
      "    Query 524835: 0.0\n",
      "    Query 524848: 0.0\n",
      "    Query 1051211: 0.1\n",
      "Recall@1000 for the Siamese Network with Triplet Loss model:\n",
      "  > 1.0\n",
      "  Computed for query 789292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if EVALUATE_MODELS:\n",
    "    print(\"Evaluating the Siamese Network model...\")\n",
    "    siamese_net_map_k = evaluation.compute_mean_average_precision_at_k(\n",
    "        MODEL_TYPES.SIAMESE_NETWORK, queries_dict, docs_dict,\n",
    "        k_documents=MAP_K, n_queries=MAP_N,\n",
    "        print_debug=PRINT_EVALUATION_DEBUG,\n",
    "        # Keyword arguments for the Siamese Network model\n",
    "        model=siamese_network_model)\n",
    "    # Evaluate the Siamese Network model (compute the Recall@K)\n",
    "    siamese_net_recall_k = evaluation.compute_recall_at_k(\n",
    "        MODEL_TYPES.SIAMESE_NETWORK, queries_dict, docs_dict,\n",
    "        k_documents=RECALL_K,\n",
    "        print_debug=PRINT_EVALUATION_DEBUG,\n",
    "        # Keyword arguments for the Siamese Network model\n",
    "        model=siamese_network_model)\n",
    "    # Print the evaluation results\n",
    "    print_model_evaluation_results(siamese_net_map_k, siamese_net_recall_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# <a id='toc7_'></a>[ü§ñ Seq2Seq Transformer Model (DSI approach)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we implement 3 possible versions of a **Seq2Seq transformer model** to act as the final model for the evaluation of the **Differentiable Search Index** approach.\n",
    "\n",
    "The **Seq2Seq transformer models** are trained to generate a **sorted list of document IDs** in response to a given **query**.\n",
    "\n",
    "The 3 transformer models, described in detail in the sub-sections below, are:\n",
    "\n",
    "1. **Seq2Seq Transformer Model using _teacher forcing_**: A Seq2Seq transformer model trained using only the **teacher forcing** technique, no auto-regressive decoding is used during training.\n",
    "\n",
    "   At inference time, instead, the model uses an **auto-regressive decoding** technique to generate the sorted list of document IDs.\n",
    "\n",
    "2. **Seq2Seq Transformer Model using _auto-regressive decoding_**: A Seq2Seq transformer model trained using only the **auto-regressive decoding** technique, no teacher forcing is used during training.\n",
    "\n",
    "   This model also uses the same **auto-regressive decoding** technique at inference time to generate the sorted list of document IDs.\n",
    "\n",
    "3. **Seq2Seq Transformer Model using _scheduled sampling_**: A Seq2Seq transformer model trained using the **scheduled sampling** technique, which consists of training the model using a mix of teacher forcing and auto-regressive decoding, by using tokens taken from either the ground truth or the model's own predictions during training, based on a probability defined by the `scheduled_sampling_decay` hyperparameter.\n",
    "\n",
    "   Once again, the model uses only the **auto-regressive decoding** technique at inference time to generate the sorted list of document IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the max length of the document IDS\n",
    "if REMAP_DOC_IDS:\n",
    "    # Doc IDs are remapped to a range [0, n_docs-1], so the max length depends on the number of documents\n",
    "    doc_ids_max_length = int(math.floor(math.log10(len(docs_dict))) + 1)\n",
    "else:\n",
    "    # We calculate the max length of the doc IDs as the length of the longest doc ID\n",
    "    doc_ids_max_length = max([len(doc_id) for doc_id in docs_dict])\n",
    "\n",
    "# Number of output tokens for the encoded document IDs (the 10 digits [0-9] plus the special tokens, i.e. end of sequence, padding, start of sequence)\n",
    "output_tokens = 10 + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc7_1_1_1_'></a>[Transformer Datasets Creation](#toc0_)\n",
    "\n",
    "We create the **datasets** to train and evaluate the **Seq2Seq transformer models** using the `Seq2SeqDataset` class.\n",
    "\n",
    "Two different datasets are created:\n",
    "\n",
    "- **Indexing Dataset**: A dataset to train the model for the **indexing task**, in which the model learns to generate document IDs starting from **documents' text embeddings** as source sequences.\n",
    "\n",
    "   Items of the dataset have the form **`(encoded_document, encoded_doc_id)`** where `encoded_document` is the tokenized version of the document's text (i.e. a **vector of word token IDs** in the tokenizer's vocabulary), computed using a pretrained **BERT** model, and `encoded_doc_id` is a tokenized version of the document's ID in the documents dictionary, computed using an ad-hoc tokenizer which maps each digit of the document ID to an index (which is the same as the digit itself), and adds a special padding token, a special start-of-sequence token, and a special end-of-sequence token.\n",
    "\n",
    "- **Retrieval Dataset**: A dataset to train the model for the **retrieval task**, in which the model learns to generate document IDs starting from **queries' text embeddings** as source sequences.\n",
    "\n",
    "   Items of the dataset have the form **`(encoded_query, encoded_doc_id)`** where `encoded_query` is the tokenized version of the query's text, computed using the same **BERT** model, and `encoded_doc_id` is the tokenized version of the document's ID in the documents dictionary, computed using the same ad-hoc tokenizer used for the **Indexing Dataset**.\n",
    "\n",
    "Both datasets are shared among the 3 transformer models for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Transformer Indexing Dataset from src/data/transformer_indexing_dataset.json...\n",
      "Loaded 979 documents from src/data/transformer_indexing_dataset.json\n",
      "Loading the Transformer Retrieval Dataset from src/data/transformer_retrieval_dataset.json...\n",
      "Loaded 1006 encoded queries and document IDs from src/data/transformer_retrieval_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets for the transformer model (datasets are shared between the 3 transformer models)\n",
    "transformer_indexing_dataset = datasets.TransformerIndexingDataset(\n",
    "    documents=docs_dict,\n",
    "    doc_id_max_length=doc_ids_max_length,\n",
    "    doc_max_length=TRANSFORMER_DOCUMENT_MAX_TOKENS,\n",
    "    dataset_file_path=DATA_FOLDER + \"/transformer_indexing_dataset.json\",\n",
    "    force_dataset_rebuild=FORCE_DICTIONARIES_REBUILD)\n",
    "transformer_retrieval_dataset = datasets.TransformerRetrievalDataset(\n",
    "    documents=docs_dict, queries=queries_dict,\n",
    "    doc_id_max_length=doc_ids_max_length,\n",
    "    query_max_length=TRANSFORMER_QUERY_MAX_TOKENS,\n",
    "    dataset_file_path=DATA_FOLDER + \"/transformer_retrieval_dataset.json\",\n",
    "    force_dataset_rebuild=FORCE_DICTIONARIES_REBUILD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print some **examples** of the **Indexing Dataset** and the **Retrieval Dataset** to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a <encoded_doc, encoded_doc_id> pair:\n",
      "  Encoded document:\n",
      "   tensor([  101, 16510,  4923,  3556,  3957, 18496,  2545,  2175,  1011,  3805,\n",
      "         3198,  3477, 11780,  2769,  6165,  2920,  7511,  2482,  5414,  1529,\n",
      "         2030,  2919,  4923,  3556,  2482,  5414,  2130,  2190,  2482,  5414,\n",
      "         4923,  3556,  8146,  9699,  3037,  6165,  2210,  3020,  7957, 10940,\n",
      "         2164, 14344,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "  Encoded document ID:\n",
      "   tensor([12,  6,  7,  9, 10, 11, 11])\n",
      "Example of a <encoded_query, encoded_doc_id> pair:\n",
      "  Encoded query:\n",
      "   tensor([  101,  4496, 24901,  3723,  4179, 16250,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n",
      "  Encoded relevant document ID:\n",
      "   tensor([12,  7,  1,  4, 10, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# Print some examples of the Transformers datasets\n",
    "print_dataset_examples = True\n",
    "if print_dataset_examples:\n",
    "    print(\"Example of a <encoded_doc, encoded_doc_id> pair:\")\n",
    "    encoded_doc, encoded_doc_id = transformer_indexing_dataset[random.randint(\n",
    "        0, len(transformer_indexing_dataset) - 1)]\n",
    "    print(\"  Encoded document:\\n  \", encoded_doc)\n",
    "    print(\"  Encoded document ID:\\n  \", encoded_doc_id)\n",
    "    print(\"Example of a <encoded_query, encoded_doc_id> pair:\")\n",
    "    encoded_query, encoded_relevant_doc_id = transformer_retrieval_dataset[random.randint(\n",
    "        0, len(transformer_retrieval_dataset) - 1)]\n",
    "    print(\"  Encoded query:\\n  \", encoded_query)\n",
    "    print(\"  Encoded relevant document ID:\\n  \", encoded_relevant_doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc7_1_1_2_'></a>[Transformer Models Initialization & Training](#toc0_)\n",
    "\n",
    "We create an auxiliary function to **initialize, train and evaluate** the **3 Seq2Seq transformer models**.\n",
    "\n",
    "The function considers the same constants and hyperparameters for all the Transformer model's different versions, with the exception of the parameters used for training.\n",
    "\n",
    "Each of the 3 Transformer models uses a different training approach (as explained in the introduction of this section), and then plots the training metrics (loss, accuracy, etc...) using the **Weights & Biases logger** for both training phases.\n",
    "\n",
    "Note that at inference time, in order to retrieve the top `K` most relevant documents, all the different Transformer models use the same **auto-regressive decoding** technique (generating document IDs' tokens one at a time, conditioning the generation of the next token on the previously generated tokens).\n",
    "\n",
    "For each model, we first train for the **indexing task**, using the `TransformerIndexingDataset` dataset, then train for the **retrieval task**, using the `TransformerRetrievalDataset` dataset (defined above).\n",
    "\n",
    "Before starting to train each model for the retrieval task, the retrieval dataset is split into a **training**, **validation** and **test** set: the latter is then used to evaluate the models' performance, thus for computing the **Mean Average Precision** and the **Recall at K**.\n",
    "\n",
    "For **computing the evaluation metrics**, we use a similar approach to the one used for the **Word2Vec** and **Siamese Network** models, but with the difference than in this case, while **training the model requires longer** than the previously described models (used as baselines), the **retrieval phase is significantly faster**, as the model directly optputs document IDs relevant to the query given as input, thus not requiring to compute the cosine similarity between the query and the entire documents corpus to find the top `K` most relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_dsi_transformer(transformer_type):\n",
    "    ''' Auxiliary function to train (or load checkpoints), show training results, and evaluate the transformer model of the given type '''\n",
    "\n",
    "    # args to pass to the dsi transformer model\n",
    "    use_scheduled_sampling_decay = \\\n",
    "        transformer_type == models.DSITransformer.TRANSFORMER_TYPES.SCHEDULED_SAMPLING_TRANSFORMER\n",
    "    dsi_transformer_args = {\n",
    "        \"tokens_in_vocabulary\": transformer_indexing_dataset.tokenizer.vocab_size,\n",
    "        \"embeddings_size\": TRANSFORMER_EMBEDDINGS_SIZE,\n",
    "        \"target_tokens\": output_tokens,\n",
    "        \"transformer_heads\": 4,\n",
    "        \"layers\": 3,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 0.00075,\n",
    "        \"batch_size\": 512,\n",
    "        \"transformer_type\": transformer_type,\n",
    "        \"scheduled_sampling_decay\": 0.015 if use_scheduled_sampling_decay else 0.0\n",
    "    }\n",
    "\n",
    "    # Initialize transformer model (using scheduled sampling)\n",
    "    transformer_model = models.DSITransformer(\n",
    "        **dsi_transformer_args)\n",
    "\n",
    "    # Model's checkpoint path\n",
    "    model_type_string = \"\"\n",
    "    if transformer_type == models.DSITransformer.TRANSFORMER_TYPES.SCHEDULED_SAMPLING_TRANSFORMER:\n",
    "        model_type_string = \"scheduled_sampling\"\n",
    "    elif transformer_type == models.DSITransformer.TRANSFORMER_TYPES.AUTOREGRESSIVE_TRANSFORMER:\n",
    "        model_type_string = \"autoregressive\"\n",
    "    elif transformer_type == models.DSITransformer.TRANSFORMER_TYPES.TEACHER_FORCINIG_TRANSFORMER:\n",
    "        model_type_string = \"teacher_forcing\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid transformer type: {transformer_type}\")\n",
    "    model_checkpoint_file = MODELS_FOLDER + \"/\" + \\\n",
    "        model_type_string + \"_\" + \\\n",
    "        MODEL_CHECKPOINTS_FILES[MODEL_TYPES.DSI_TRANSFORMER]\n",
    "\n",
    "    # Train the model or load its saved checkpoint\n",
    "    transformer_retrieval_test_set = None\n",
    "    transformer_retrieval_test_set_file = DATA_FOLDER + \\\n",
    "        f\"/{model_type_string}_transformer_retrieval_test_set.json\"\n",
    "    if LOAD_MODELS_CHECKPOINTS and os.path.exists(model_checkpoint_file):\n",
    "        # Load the saved models checkpoint\n",
    "        print(\"A checkpoint for the model exist, loading the saved model checkpoint...\")\n",
    "        transformer_model = models.DSITransformer.load_from_checkpoint(\n",
    "            model_checkpoint_file, **dsi_transformer_args)\n",
    "        print(\"Model checkpoint loaded.\")\n",
    "        # Load the transformer retrieval test set from the JSON file\n",
    "        print(\"Loading the transformer retrieval test set from the JSON file...\")\n",
    "        with open(transformer_retrieval_test_set_file, \"r\") as transformer_retrieval_test_set_file:\n",
    "            transformer_retrieval_test_set = json.load(\n",
    "                transformer_retrieval_test_set_file)\n",
    "        print(\"Transformer retrieval test set loaded.\")\n",
    "    else:\n",
    "        # Create 2 loggers for the transformer model (one for the indexing task and one for the retrieval task)\n",
    "        transformer_loggers = None\n",
    "        if wandb_api is not None:\n",
    "            transformer_wandb_logger_indexing = WandbLogger(\n",
    "                log_model=\"all\", project=wandb_project, name=transformer_type + \" (Indexing)\")\n",
    "            transformer_wandb_logger_retrieval = WandbLogger(\n",
    "                log_model=\"all\", project=wandb_project, name=transformer_type + \" (Retrieval)\")\n",
    "            transformer_loggers = [transformer_wandb_logger_indexing,\n",
    "                                   transformer_wandb_logger_retrieval]\n",
    "        # Train the transformer model (with scheduled sampling) for the indexing task\n",
    "        transformer_training_infos = training.train_transformer(\n",
    "            transformer_indexing_dataset=transformer_indexing_dataset,\n",
    "            transformer_retrieval_dataset=transformer_retrieval_dataset,\n",
    "            transformer_model=transformer_model,\n",
    "            max_epochs_list=[2, 2],\n",
    "            batch_size=transformer_model.hparams.batch_size,\n",
    "            indexing_split_ratios=(0.8, 0.2),\n",
    "            retrieval_split_ratios=(0.75, 0.175, 0.075),\n",
    "            logger=transformer_loggers,\n",
    "            save_path=model_checkpoint_file\n",
    "        )\n",
    "        # Show the wandb training run's dashboard\n",
    "        if wandb_api is not None:\n",
    "            print(\n",
    "                f\"Indexing training results for the {transformer_type} model:\")\n",
    "            indexing_run_id = transformer_training_infos[\"run_ids\"][\"indexing\"]\n",
    "            indexing_run_object: wandb_run.Run = wandb_api.run(\n",
    "                f\"{wandb_entity}/{wandb_project}/{indexing_run_id}\")\n",
    "            indexing_run_object.display(height=1000)\n",
    "            print(\n",
    "                f\"Retrieval training results for the {transformer_type} model:\")\n",
    "            retrieval_run_id = transformer_training_infos[\"run_ids\"][\"retrieval\"]\n",
    "            retrieval_run_object: wandb_run.Run = wandb_api.run(\n",
    "                f\"{wandb_entity}/{wandb_project}/{retrieval_run_id}\")\n",
    "            retrieval_run_object.display(height=1000)\n",
    "        # Save the generated transformer retrieval test set to the JSON file\n",
    "        print(\"Saving the transformer retrieval test set to the JSON file...\")\n",
    "        retrieval_test_dataset = transformer_training_infos[\"retrieval\"][\"test\"]\n",
    "        transformer_retrieval_test_set = {\n",
    "            \"encoded_queries\": [],\n",
    "            \"encoded_doc_ids\": []\n",
    "        }\n",
    "        retrieval_test_dataset_length = retrieval_test_dataset.__len__()\n",
    "        for i in range(retrieval_test_dataset_length):\n",
    "            encoded_query, doc_id = retrieval_test_dataset.__getitem__(i)\n",
    "            transformer_retrieval_test_set[\"encoded_queries\"].append(\n",
    "                encoded_query.tolist())\n",
    "            transformer_retrieval_test_set[\"encoded_doc_ids\"].append(\n",
    "                doc_id.tolist())\n",
    "        with open(transformer_retrieval_test_set_file, \"w\") as transformer_retrieval_test_set_file:\n",
    "            json.dump(transformer_retrieval_test_set,\n",
    "                      transformer_retrieval_test_set_file)\n",
    "\n",
    "    # Evaluate the transformer model (for the retrieval task)\n",
    "    if EVALUATE_MODELS:\n",
    "        transformer_retrieval_map_k = evaluation.compute_mean_average_precision_at_k(\n",
    "            MODEL_TYPES.DSI_TRANSFORMER, queries_dict, docs_dict,\n",
    "            k_documents=MAP_K, n_queries=MAP_N,\n",
    "            print_debug=PRINT_EVALUATION_DEBUG,\n",
    "            # Keyword arguments for the Transformer model\n",
    "            model=transformer_model, retrieval_dataset=transformer_retrieval_dataset, retrieval_test_set=transformer_retrieval_test_set)\n",
    "        transformer_retrieval_recall_k = evaluation.compute_recall_at_k(\n",
    "            MODEL_TYPES.DSI_TRANSFORMER, queries_dict, docs_dict,\n",
    "            k_documents=RECALL_K,\n",
    "            print_debug=PRINT_EVALUATION_DEBUG,\n",
    "            # Keyword arguments for the Transformer model\n",
    "            model=transformer_model, retrieval_dataset=transformer_retrieval_dataset, retrieval_test_set=transformer_retrieval_test_set)\n",
    "        print_model_evaluation_results(transformer_retrieval_map_k,\n",
    "                                       transformer_retrieval_recall_k)\n",
    "\n",
    "    return transformer_model, transformer_retrieval_map_k, transformer_retrieval_recall_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6_1\"></a>\n",
    "\n",
    "## <a id='toc7_2_'></a>[Teacher Forcing Seq2Seq Transformer Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first version of the **Seq2Seq transformer model** is trained using only the **teacher forcing** technique, no auto-regressive decoding is used during training.\n",
    "\n",
    "This means that, during training, the model is fed with the **ground truth** document IDs as target sequences, and is therefore trained to generate the correct document IDs given both the query and the ground truth document IDs as input.\n",
    "\n",
    "At inference time, the model uses the usual **auto-regressive decoding** technique to generate token weights (instead of probabilities, as no softmax is applied to the output of the Transformer model) for all possible document IDs tokens.\n",
    "\n",
    "We **train the model** and then, if a `WANDB_API_KEY` was provided, we also load the **Weights & Biases** dashboard to **plot the training results** for both the indexing and retrieval tasks (in this order).\n",
    "\n",
    "After training, we then evaluate the Transformer model by computing the usual **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **teacher forcing Seq2Seq transformer model**.\n",
    "\n",
    "We then **print the results** of the evaluation of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_folder: src/models/\n",
      "checkpoint_name: teacher_forcing_transformer.ckpt\n",
      "Training the model for the indexing task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_014011-k7u7u43n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/k7u7u43n/workspace' target=\"_blank\">Teacher Forcing Transformer (Indexing)</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/k7u7u43n/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/k7u7u43n/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | model                | Transformer        | 201 K \n",
      "1 | get_input_embedding  | Embedding          | 2.0 M \n",
      "2 | get_target_embedding | Embedding          | 832   \n",
      "3 | positional_encoder   | PositionalEncoding | 0     \n",
      "4 | output_layer         | Linear             | 845   \n",
      "5 | cross_entropy_loss   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.628     Total estimated model params size (MB)\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.36it/s, v_num=u43n]\n",
      "Average training loss for epoch 0:  2.5790724754333496\n",
      "Average validation loss for epoch 0:  2.378133773803711\n",
      "Average training accuracy for epoch 0:  0.12852619588375092\n",
      "Average validation accuracy for epoch 0:  0.2568807303905487\n",
      "Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:03<00:03,  0.29it/s, v_num=u43n]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.37it/s, v_num=u43n]\n",
      "Average training loss for epoch 1:  2.3914284706115723\n",
      "Average validation loss for epoch 1:  2.3206422328948975\n",
      "Average training accuracy for epoch 1:  0.25645875930786133\n",
      "Average validation accuracy for epoch 1:  0.2568807303905487\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  0.23it/s, v_num=u43n]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  0.22it/s, v_num=u43n]\n",
      "Trained the model for the indexing task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Teacher Forcing Transformer (Indexing)</strong> at: <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/k7u7u43n/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/k7u7u43n/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for the retrieval task...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_014113-859l1jv8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/859l1jv8/workspace' target=\"_blank\">Teacher Forcing Transformer (Retrieval)</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/859l1jv8/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/859l1jv8/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | model                | Transformer        | 201 K \n",
      "1 | get_input_embedding  | Embedding          | 2.0 M \n",
      "2 | get_target_embedding | Embedding          | 832   \n",
      "3 | positional_encoder   | PositionalEncoding | 0     \n",
      "4 | output_layer         | Linear             | 845   \n",
      "5 | cross_entropy_loss   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.628     Total estimated model params size (MB)\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.47it/s, v_num=1jv8]\n",
      "Average training loss for epoch 0:  2.3551197052001953\n",
      "Average validation loss for epoch 0:  2.2969632148742676\n",
      "Average training accuracy for epoch 0:  0.25449585914611816\n",
      "Average validation accuracy for epoch 0:  0.2569343149662018\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.22it/s, v_num=1jv8]\n",
      "Average training loss for epoch 1:  2.3072762489318848\n",
      "Average validation loss for epoch 1:  2.2692878246307373\n",
      "Average training accuracy for epoch 1:  0.25836020708084106\n",
      "Average validation accuracy for epoch 1:  0.2569343149662018\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.54it/s, v_num=1jv8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.16it/s, v_num=1jv8]\n",
      "Trained the model for the retrieval task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Teacher Forcing Transformer (Retrieval)</strong> at: <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/859l1jv8/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/859l1jv8/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing training results for the Teacher Forcing Transformer model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/k7u7u43n?jupyter=true' style='border:none;width:100%;height:1000px;'></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval training results for the Teacher Forcing Transformer model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/859l1jv8?jupyter=true' style='border:none;width:100%;height:1000px;'></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the transformer retrieval test set to the JSON file...\n",
      "Evaluating DSI Transformer model to compute MAP@K...\n",
      "Top 10 (predicted) document IDs for query 1/10:\n",
      "  ['45', '66', '242', '24', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['920', '105', '14', '204', '315', '411', '455', '499', '500', '609', '752']\n",
      "  Precision at 10 for query 1/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 2/10:\n",
      "  ['26', '4', '7', '0', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['906', '109', '119', '144', '20', '359', '528', '585', '665', '683']\n",
      "  Precision at 10 for query 2/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 3/10:\n",
      "  ['476', '4', '646', '7', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['952', '352', '632', '707', '762', '764', '771', '778', '781', '789']\n",
      "  Precision at 10 for query 3/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 4/10:\n",
      "  ['4', '44', '266', '66', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['861', '12', '244', '347', '368', '422', '518', '524', '631', '645']\n",
      "  Precision at 10 for query 4/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 5/10:\n",
      "  ['44', '444', '22', '2', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['971', '148', '229', '364', '365', '466', '572', '724', '725', '751']\n",
      "  Precision at 10 for query 5/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 6/10:\n",
      "  ['44', '44', '94', '5', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['846', '78', '79', '14', '48', '609', '698', '752', '796', '804', '920']\n",
      "  Precision at 10 for query 6/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 7/10:\n",
      "  ['444', '4', '6', '2', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['819', '192', '203', '417', '419', '511', '582', '624', '682', '695', '837']\n",
      "  Precision at 10 for query 7/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 8/10:\n",
      "  ['4', '444', '624', '6', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['888', '84', '135', '438', '442', '493', '514', '584', '588', '610']\n",
      "  Precision at 10 for query 8/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 9/10:\n",
      "  ['4', '0', '7566', '756', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['65', '904', '330', '405', '554', '555', '625', '676', '687', '709']\n",
      "  Precision at 10 for query 9/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 10/10:\n",
      "  ['4', '2', '44', '444', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['901', '2', '160', '310', '410', '469', '542', '737', '748', '759']\n",
      "  Precision at 10 for query 10/10: 0.1\n",
      "Evaluating DSI Transformer model to compute Recall@K...\n",
      "Top 1000 (predicted) document IDs for query 525868:\n",
      "  ['44', '444', '4', '4', '44', '4', '4', '444', '4', '444', '44', '0', '444', '44', '444', '444', '4', '978', '0', '4', '44', '44', '444', '444', '4', '0', '44', '44', '444', '4', '4', '44', '44', '4', '44', '4', '44', '4', '4', '44', '4', '444', '44', '44', '444', '44', '44', '44', '44', '444', '4', '44', '44', '44', '4', '44', '44', '44', '0', '0', '444', '4444', '4', '444', '44', '44', '44', '44', '4', '978', '4', '44', '444', '4', '44', '44', '4', '444', '44', '4', '44', '444', '4', '444', '978', '44', '44', '444', '4444', '44', '978', '4', '444', '4', '44', '44', '0', '4', '4', '44', '4444', '44', '4', '0', '44', '444', '44', '44', '44', '444', '444', '4', '978', '978', '978', '4', '44', '4', '44', '444', '4', '44', '4', '4', '444', '44', '44', '44', '44', '4', '0', '4', '44', '444', '4', '4', '44', '978', '44', '4', '978', '44', '4', '4', '44', '4', '44', '44', '978', '444', '44', '444', '0', '4', '4', '44', '978', '44', '4', '4', '444', '0', '978', '4', '44', '4', '4', '4', '44', '44', '44', '444', '4444', '444', '44', '444', '4', '4', '0', '44', '4', '444', '44', '4', '4', '444', '44', '44', '444', '4', '4', '4444', '4', '44', '44', '444', '44', '444', '4', '4', '778', '77', '728', '7', '772', '777', '78', '0', '978', '72', '77', '72', '7', '772', '772', '7', '77', '77', '7', '2', '978', '7', '77', '7', '728', '8', '778', '7', '8', '78', '78', '77', '7', '7', '7', '72', '77', '778', '72', '2', '7', '7', '0', '778', '7', '72', '72', '72', '978', '7', '728', '728', '7', '72', '7', '77', '7', '728', '978', '7', '7', '72', '78', '777', '72', '777', '77', '78', '728', '7', '7', '2', '77', '78', '7', '777', '772', '72', '72', '777', '772', '7', '77', '2', '7', '0', '77', '978', '728', '0', '7', '7', '978', '0', '2', '7', '7', '28', '7', '7', '7', '7', '77', '28', '7', '7', '7', '78', '7', '72', '728', '978', '77', '28', '777', '772', '777', '978', '78', '78', '7', '77', '7', '2', '77', '7', '77', '7', '7', '777', '777', '77', '7', '978', '728', '778', '777', '7', '7', '728', '28', '978', '7', '28', '7772', '778', '77', '7772', '728', '978', '7', '7', '7', '7', '7', '7772', '7', '0', '7', '7', '7', '7', '77', '7', '7', '7', '978', '2', '0', '7', '77', '77', '728', '7', '77', '7', '77', '28', '7', '7', '728', '7', '7772', '777', '7', '7', '77', '778', '78', '7', '28', '77', '978', '7', '7', '7', '978', '77', '778', '78', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['923', '102', '173', '178', '212', '394', '617', '623', '648', '649']\n",
      "MAP@10 for the DSI Transformer model:\n",
      "  > 0.01\n",
      "  Computed on 10 queries\n",
      "  Single queries precision:\n",
      "    Query 263670: 0.0\n",
      "    Query 264410: 0.0\n",
      "    Query 1050747: 0.0\n",
      "    Query 1051372: 0.0\n",
      "    Query 788484: 0.0\n",
      "    Query 264827: 0.0\n",
      "    Query 524733: 0.0\n",
      "    Query 1050231: 0.0\n",
      "    Query 2962: 0.0\n",
      "    Query 1048585: 0.1\n",
      "Recall@1000 for the DSI Transformer model:\n",
      "  > 0.0\n",
      "  Computed for query 525868\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the transformer model using only teacher forcing\n",
    "teacher_forcing_transformer, teacher_forcing_transformer_map_k, teacher_forcing_transformer_recall_k = \\\n",
    "    train_and_evaluate_dsi_transformer(\n",
    "        models.DSITransformer.TRANSFORMER_TYPES.TEACHER_FORCINIG_TRANSFORMER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6_1\"></a>\n",
    "\n",
    "## <a id='toc7_3_'></a>[Autoregressive Seq2Seq Transformer Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second version of the **Seq2Seq transformer model** is trained using an **auto-regressive decoding** technique, no teacher forcing is used during training.\n",
    "\n",
    "This means that, during training, the model learns to generate the correct document IDs by relying only on its own predictions, and not on the ground truth document IDs.\n",
    "\n",
    "The same **auto-regressive decoding** technique is also used at inferencing time to generate token weights (instead of probabilities, as no softmax is applied to the output of the Transformer model) for all possible document IDs tokens.\n",
    "\n",
    "We **train the model** and then, if a `WANDB_API_KEY` was provided, we also load the **Weights & Biases** dashboard to **plot the training results** for both the indexing and retrieval tasks (in this order).\n",
    "\n",
    "After training, we then evaluate the Transformer model by computing the usual **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **teacher forcing Seq2Seq transformer model**.\n",
    "\n",
    "We then **print the results** of the evaluation of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_folder: src/models/\n",
      "checkpoint_name: autoregressive_transformer.ckpt\n",
      "Training the model for the indexing task...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_014214-rz9ps40d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/rz9ps40d/workspace' target=\"_blank\">Autoregressive Transformer (Indexing)</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/rz9ps40d/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/rz9ps40d/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | model                | Transformer        | 201 K \n",
      "1 | get_input_embedding  | Embedding          | 2.0 M \n",
      "2 | get_target_embedding | Embedding          | 832   \n",
      "3 | positional_encoder   | PositionalEncoding | 0     \n",
      "4 | output_layer         | Linear             | 845   \n",
      "5 | cross_entropy_loss   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.628     Total estimated model params size (MB)\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:11<00:00,  0.03it/s, v_num=s40d]\n",
      "Average training loss for epoch 0:  2.6046524047851562\n",
      "Average validation loss for epoch 0:  2.3555748462677\n",
      "Average training accuracy for epoch 0:  0.1287824809551239\n",
      "Average validation accuracy for epoch 0:  0.25789472460746765\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:51<00:00,  0.04it/s, v_num=s40d]\n",
      "Average training loss for epoch 1:  2.357470750808716\n",
      "Average validation loss for epoch 1:  2.283738374710083\n",
      "Average training accuracy for epoch 1:  0.25692886114120483\n",
      "Average validation accuracy for epoch 1:  0.25789472460746765\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:55<00:00,  0.04it/s, v_num=s40d]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:56<00:00,  0.04it/s, v_num=s40d]\n",
      "Trained the model for the indexing task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Autoregressive Transformer (Indexing)</strong> at: <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/rz9ps40d/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/rz9ps40d/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for the retrieval task...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_014504-5v7x4zji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/5v7x4zji/workspace' target=\"_blank\">Autoregressive Transformer (Retrieval)</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/5v7x4zji/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/5v7x4zji/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | model                | Transformer        | 201 K \n",
      "1 | get_input_embedding  | Embedding          | 2.0 M \n",
      "2 | get_target_embedding | Embedding          | 832   \n",
      "3 | positional_encoder   | PositionalEncoding | 0     \n",
      "4 | output_layer         | Linear             | 845   \n",
      "5 | cross_entropy_loss   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.628     Total estimated model params size (MB)\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  0.32it/s, v_num=4zji]\n",
      "Average training loss for epoch 0:  2.3218514919281006\n",
      "Average validation loss for epoch 0:  2.238758087158203\n",
      "Average training accuracy for epoch 0:  0.2557554841041565\n",
      "Average validation accuracy for epoch 0:  0.25581395626068115\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.40it/s, v_num=4zji]\n",
      "Average training loss for epoch 1:  2.2694759368896484\n",
      "Average validation loss for epoch 1:  2.224186658859253\n",
      "Average training accuracy for epoch 1:  0.26055797934532166\n",
      "Average validation accuracy for epoch 1:  0.25581395626068115\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.36it/s, v_num=4zji]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  0.33it/s, v_num=4zji]\n",
      "Trained the model for the retrieval task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Autoregressive Transformer (Retrieval)</strong> at: <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/5v7x4zji/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/5v7x4zji/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing training results for the Autoregressive Transformer model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/rz9ps40d?jupyter=true' style='border:none;width:100%;height:1000px;'></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval training results for the Autoregressive Transformer model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/5v7x4zji?jupyter=true' style='border:none;width:100%;height:1000px;'></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the transformer retrieval test set to the JSON file...\n",
      "Evaluating DSI Transformer model to compute MAP@K...\n",
      "Top 10 (predicted) document IDs for query 1/10:\n",
      "  ['55', '537', '63', '5', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['968', '969', '86', '216', '372', '519', '536', '653', '674', '749']\n",
      "  Precision at 10 for query 1/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 2/10:\n",
      "  ['8', '7', '3', '333', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['891', '892', '895', '893', '891', '894', '890']\n",
      "  Precision at 10 for query 2/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 3/10:\n",
      "  ['37', '978', '83', '8', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['921', '404', '480', '50', '598', '6', '664', '706', '723', '746']\n",
      "  Precision at 10 for query 3/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 4/10:\n",
      "  ['8', '77', '6', '3', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['927', '71', '126', '176', '213', '256', '324', '361', '402', '5']\n",
      "  Precision at 10 for query 4/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 5/10:\n",
      "  ['37', '8', '475', '54', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['960', '353', '478', '704', '745', '8', '803', '62', '808', '1']\n",
      "  Precision at 10 for query 5/10: 0.1\n",
      "Top 10 (predicted) document IDs for query 6/10:\n",
      "  ['8377', '377', '65', '553', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['914', '100', '117', '316', '339', '407', '419', '530', '531', '534']\n",
      "  Precision at 10 for query 6/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 7/10:\n",
      "  ['8', '377', '53', '978', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['888', '84', '135', '438', '442', '493', '514', '584', '588', '610']\n",
      "  Precision at 10 for query 7/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 8/10:\n",
      "  ['8', '377', '533', '978', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['901', '2', '160', '310', '410', '469', '542', '737', '748', '759']\n",
      "  Precision at 10 for query 8/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 9/10:\n",
      "  ['8', '8', '657', '7', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['883', '145', '220', '283', '284', '346', '421', '446', '447', '464', '858']\n",
      "  Precision at 10 for query 9/10: 0.0\n",
      "Top 10 (predicted) document IDs for query 10/10:\n",
      "  ['3', '8', '4', '5', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['885', '977', '185', '845', '884', '975', '886', '304', '826', '887']\n",
      "  Precision at 10 for query 10/10: 0.0\n",
      "Evaluating DSI Transformer model to compute Recall@K...\n",
      "Top 1000 (predicted) document IDs for query 1051886:\n",
      "  ['5', '5', '5', '53', '373', '33', '33', '53', '5', '337', '53', '37', '37', '5337', '53', '3', '373', '337', '53', '373', '978', '33', '3', '337', '373', '5', '5337', '3', '53', '33', '337', '5', '0', '53', '73', '373', '978', '373', '978', '5337', '533', '533', '5', '978', '33', '978', '3', '37', '33', '373', '37', '373', '33', '978', '53', '73', '3', '37', '7', '337', '373', '33', '37', '53', '5337', '0', '53', '5', '5', '7', '5', '373', '53', '978', '978', '5', '533', '5', '33', '3', '5337', '5337', '37', '5', '5', '5', '33', '373', '3', '337', '37', '333', '3', '33', '3', '33', '5', '5', '3', '5', '978', '373', '7', '0', '73', '978', '5', '0', '533', '53', '53', '533', '53', '5', '53', '37', '0', '37', '5337', '533', '73', '373', '5', '5', '0', '7', '3', '53', '53', '53', '5', '5', '373', '3', '33', '373', '33', '5', '373', '5', '5', '978', '33', '373', '373', '533', '53', '53', '7', '3', '53', '373', '373', '3', '533', '978', '333', '53', '37', '5337', '5', '5', '37', '33', '3', '5', '333', '5', '373', '5337', '5', '3', '73', '5', '37', '373', '533', '3', '373', '33', '533', '373', '37', '333', '373', '373', '73', '33', '7', '337', '37', '53', '373', '978', '0', '5', '37', '53', '333', '533', '8', '5', '557', '8', '85', '8', '5', '8', '8555', '8', '8', '557', '555', '8', '8555', '85', '85', '8', '55', '557', '8', '8', '85', '557', '855', '978', '57', '855', '55', '57', '557', '57', '557', '5', '555', '55', '8', '8', '8', '57', '0', '557', '55', '55', '557', '55', '0', '7', '557', '57', '85', '8', '85', '8', '557', '8', '978', '8', '8', '8555', '8', '855', '55', '855', '55', '55', '8', '85', '555', '57', '978', '855', '85', '85', '555', '55', '85', '85', '978', '5', '8', '978', '85', '55', '8555', '55', '85', '55', '7', '5', '57', '557', '57', '8', '855', '85', '55', '85', '978', '8', '557', '978', '85', '978', '55', '8555', '8', '557', '57', '557', '8', '8', '5', '57', '0', '8555', '85', '8', '55', '0', '55', '5', '85', '8', '57', '8', '55', '57', '8', '0', '5', '8', '55', '8', '7', '57', '0', '8', '85', '557', '57', '8555', '8', '8', '855', '8555', '8555', '8', '8', '57', '8', '5', '557', '85', '85', '57', '557', '85', '0', '85', '5', '5', '557', '5', '557', '55', '5', '8', '557', '557', '57', '57', '5', '8', '557', '0', '978', '57', '978', '55', '8', '8', '8', '8', '8', '57', '8', '7', '978', '5', '55', '978', '555', '55', '8', '0', '7', '555', '8555', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978', '978']\n",
      "> Actual relevant document IDs for the query:\n",
      "  ['933', '99', '49', '620', '720', '738', '768', '775', '779', '797', '803']\n",
      "MAP@10 for the DSI Transformer model:\n",
      "  > 0.01\n",
      "  Computed on 10 queries\n",
      "  Single queries precision:\n",
      "    Query 1050670: 0.0\n",
      "    Query 1049791: 0.0\n",
      "    Query 2235: 0.0\n",
      "    Query 437291: 0.0\n",
      "    Query 1051095: 0.1\n",
      "    Query 524835: 0.0\n",
      "    Query 1050231: 0.0\n",
      "    Query 1048585: 0.0\n",
      "    Query 1050695: 0.0\n",
      "    Query 1050275: 0.0\n",
      "Recall@1000 for the DSI Transformer model:\n",
      "  > 0.0\n",
      "  Computed for query 1051886\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the transformer model using ony an autoregressive approach\n",
    "autoregressive_transformer, autoregressive_transformer_map_k, autoregressive_transformer_recall_k = \\\n",
    "    train_and_evaluate_dsi_transformer(\n",
    "        models.DSITransformer.TRANSFORMER_TYPES.AUTOREGRESSIVE_TRANSFORMER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6_3\"></a>\n",
    "\n",
    "## <a id='toc7_4_'></a>[Scheduled Sampling Seq2Seq Transformer Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final version of the **Seq2Seq transformer model** is trained using the **scheduled sampling** technique, which consists of training the model using a mix of teacher forcing and auto-regressive decoding, by using tokens taken from either the ground truth or the model's own predictions during training, based on a certain probability: this probability is initially set to 1.0 and then decays linearly over time, after each training epoch, by a factor defined by the `scheduled_sampling_decay` hyperparameter.\n",
    "\n",
    "During training, at each new token generation, the model decides whether to use the ground truth token (teacher forcing) or the previously generated token (autoregression) as input for the next token generation, based on the current probability.\n",
    "\n",
    "At inference time, only the **auto-regressive decoding** approach is used to generate token weights (instead of probabilities, as no softmax is applied to the output of the Transformer model) for all possible document IDs tokens.\n",
    "\n",
    "We **train the model** and then, if a `WANDB_API_KEY` was provided, we also load the **Weights & Biases** dashboard to **plot the training results** for both the indexing and retrieval tasks (in this order).\n",
    "\n",
    "After training, we then evaluate the Transformer model by computing the usual **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **teacher forcing Seq2Seq transformer model**.\n",
    "\n",
    "We then **print the results** of the evaluation of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_folder: src/models/\n",
      "checkpoint_name: scheduled_sampling_transformer.ckpt\n",
      "Training the model for the indexing task...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240401_014613-j9b8kjt0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/j9b8kjt0/workspace' target=\"_blank\">Scheduled Sampling Transformer (Indexing)</a></strong> to <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valeriodstfn/dl-dsi-project/runs/j9b8kjt0/workspace' target=\"_blank\">https://wandb.ai/valeriodstfn/dl-dsi-project/runs/j9b8kjt0/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | model                | Transformer        | 201 K \n",
      "1 | get_input_embedding  | Embedding          | 2.0 M \n",
      "2 | get_target_embedding | Embedding          | 832   \n",
      "3 | positional_encoder   | PositionalEncoding | 0     \n",
      "4 | output_layer         | Linear             | 845   \n",
      "5 | cross_entropy_loss   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.628     Total estimated model params size (MB)\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  0.37it/s, v_num=kjt0]\n",
      "Scheduled sampling probability for epoch 0:  1.0\n",
      "Average training loss for epoch 0:  2.6037509441375732\n",
      "Average validation loss for epoch 0:  2.4007248878479004\n",
      "Average training accuracy for epoch 0:  0.14360859990119934\n",
      "Average validation accuracy for epoch 0:  0.25789472460746765\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  0.33it/s, v_num=kjt0]\n",
      "Scheduled sampling probability for epoch 1:  0.985\n",
      "Average training loss for epoch 1:  2.363131046295166\n",
      "Average validation loss for epoch 1:  2.296553611755371\n",
      "Average training accuracy for epoch 1:  0.25678831338882446\n",
      "Average validation accuracy for epoch 1:  0.25789472460746765\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  0.21it/s, v_num=kjt0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:10<00:00,  0.20it/s, v_num=kjt0]\n",
      "Trained the model for the indexing task.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the transformer model using scheduled sampling\n",
    "scheduled_sampling_transformer, scheduled_sampling_transformer_map_k, scheduled_sampling_transformer_recall_k = \\\n",
    "    train_and_evaluate_dsi_transformer(\n",
    "        models.DSITransformer.TRANSFORMER_TYPES.SCHEDULED_SAMPLING_TRANSFORMER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
